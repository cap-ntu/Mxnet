/*copyright (c) 2015 by Contributors
 * @file   kvstore_dist.h
 * @brief  distributed implementation based on ps-lite
 */
#ifndef MXNET_KVSTORE_KVSTORE_DIST_H_
#define MXNET_KVSTORE_KVSTORE_DIST_H_
#include <string>
#include <vector>
#include "./kvstore_local.h"
#include "mxnet/engine.h"
#include "ps/ps.h"
#include "./kvstore_dist_server.h"
#include <stdlib.h> 
#include <iostream> 
namespace mxnet {
namespace kvstore {

/**
 * \brief distributed kvstore
 *
 * for a worker node, it always guarantees that all push and pull issued from
 * this worker on the same key are serialized. namely push(3) and then pull(3),
 * then the data pulled is always containing the modification from the push(3).
 *
 * it's the server node's job to control the data consistency among all
 * workers. see details on \ref ServerHandle::Start
 */
class KVStoreDist : public KVStoreLocal {
 public:
  explicit KVStoreDist(bool use_device_comm)
      : KVStoreLocal(use_device_comm), ps_worker_(nullptr), server_(nullptr) {
    if (IsWorkerNode()) {
      ps_worker_ = new ps::KVWorker<real_t>(0);
      ps::StartAsync("mxnet\0");
      if (!ps::Postoffice::Get()->is_recovery()) {
        ps::Postoffice::Get()->Barrier(
          ps::kWorkerGroup + ps::kServerGroup + ps::kScheduler);
      }
    }
    bigarray_bound_ = dmlc::GetEnv("MXNET_KVSTORE_BIGARRAY_BOUND", 1000 * 1000);
  }

  virtual ~KVStoreDist() {
    Engine::Get()->WaitForAll();
    if (IsWorkerNode()) {
      if (barrier_before_exit_) {
        Barrier();
        if (get_rank() == 0) {
          // stop the executor at servers
          SendCommandToServers(kStopServer, "");
        }
      }
      ps::Finalize(barrier_before_exit_);
      delete ps_worker_;
    }
  }

  void Init(const std::vector<int>& keys,
            const std::vector<NDArray>& values) override {
    CheckUnique(keys);
    for (size_t i = 0; i < keys.size(); ++i) {
      comm_->Init(keys[i], values[i].shape());
    }
    if (get_rank() == 0) {
      Push_(keys, values, 0, false);
      // wait until the push is finished
      for (const auto& v : values) {
        v.WaitToWrite();
      }
    } else {
      // do nothing
    }
    if (!ps::Postoffice::Get()->is_recovery()) {
      Barrier();
    }
  }

  void Push(const std::vector<int>& keys,
            const std::vector<NDArray>& values,
            int priority) override {
    Push_(keys, values, priority, true);
  }

  void Pull(const std::vector<int>& keys,
            const std::vector<NDArray*>& values,
            int priority) override {
    std::vector<int> uniq_keys;
     static unsigned long iteration=1;
   static int constKey=-1;
   bool keyexist=true;
  
	if(constKey==-1)constKey=keys[0];
	if(constKey==keys[0])iteration++;
   std::vector<std::vector<NDArray*> > grouped_vals;
    GroupKVPairs(keys, values, &uniq_keys, &grouped_vals);
    //std::cout<<"dist-pull\n";
    for (size_t i = 0; i < uniq_keys.size(); ++i) {
      int key = uniq_keys[i];
      // use the same array for merging to guarantee that pull always happens
      // after the previous push on this key
      auto& recv_buf = comm_buf_[key];
      if (recv_buf.is_none()) {
        // it may happen for the first time a no-rank-0 worker pull the weight.
        recv_buf = NDArray(grouped_vals[i][0]->shape(), pinned_ctx_);
	keyexist=false;
      }
      real_t* data = static_cast<real_t*>(recv_buf.data().dptr_);
      size_t size = recv_buf.shape().Size();
	 float init_Threshold=dmlc::GetEnv("init_threshold",1.05);
        double  thres= std::(init_Threshold / sqrt(iteration),0.5/cbrt(iteration));
        real_t avg=0;
        real_t sum=0;
        if(keyexist && size>0 && !isnan(data[0])){
        for(size_t y=0;y<size;y++)
                sum+=fabs(data[y]);
        avg=sum/size;
	 //std::cout<<keys[i]<<" "<<avg<<" "<<thres<<"\r";
        if(avg<thres && size>0 ){
	 //  std::cout<<keys[i]<<" "<<avg<<" "<<thres<<"\r";
           return;
        }}
      auto pull_from_servers = [this, key, data, size](
          RunContext rctx, Engine::CallbackOnComplete cb) {
        // convert to ps keys
        PSKV& pskv = EncodeKey(key, size);

        // issue pull, false means no delete
        auto vals = new ps::SArray<real_t>(data, size, false);
	/* float init_Threshold=dmlc::GetEnv("init_threshold",0.1);
	static unsigned long iteration=1;
	double  thres= init_Threshold / sqrt(iteration/200);
	real_t avg=0;
	real_t sum=0;
        iteration++;
	for(size_t y=0;y<size;y++)
		sum+=fabs(data[y]);
	avg=sum/size;
	//std::cout<<avg<<" "<<thres<<"\n";
	if(avg==0 && size>0){
	   delete vals;return;
	}*/

	 CHECK_NOTNULL(ps_worker_)->ZPull(
        pskv.keys, vals, &pskv.lens, 0, [vals, cb](){ delete vals; cb(); });
      };

      CHECK_NOTNULL(Engine::Get())->PushAsync(
          pull_from_servers,
          pinned_ctx_,
          {},
          {recv_buf.var()},
          FnProperty::kNormal,
          priority,
          PROFILER_MESSAGE("KVStoreDistPull"));

      comm_->Broadcast(key, recv_buf, grouped_vals[i], priority);

  }
  }

  void set_updater(const Updater& updater) override {
    CHECK(updater) << "invalid updater";
    if (IsServerNode()) {
      CHECK_NOTNULL(server_)->set_updater(updater);
    } else {
      updater_ = updater;
    }
  }

  void Barrier() override {
    ps::Postoffice::Get()->Barrier(ps::kWorkerGroup);
  }


  void SendCommandToServers(int cmd_id,
                            const std::string& cmd_body) override {
    CHECK_NOTNULL(ps_worker_);
    ps_worker_->Wait(ps_worker_->Request(cmd_id, cmd_body, ps::kServerGroup));
  }

  int get_group_size() const override { return ps::NumWorkers(); }

  int get_rank() const override { return ps::MyRank(); }

  int get_num_dead_node(int node_id, int timeout) const override {
    int number = 0;
    auto dead_nodes = ps::Postoffice::Get()->GetDeadNodes(timeout);
    const auto& watch_nodes = ps::Postoffice::Get()->GetNodeIDs(node_id);
    std::unordered_set<int> watch_set(watch_nodes.begin(), watch_nodes.end());
    for (int r : dead_nodes) {
      if (watch_set.find(r) != watch_set.end()) number++;
    }
    return number;
  }

  void RunServer(const Controller& controller) override {
    CHECK(!IsWorkerNode());
    if (IsServerNode()) {
      server_ = new KVStoreDistServer();
      server_->set_controller(controller);
    }

    ps::StartAsync("mxnet_server\0");
    if (!ps::Postoffice::Get()->is_recovery()) {
      ps::Postoffice::Get()->Barrier(
        ps::kWorkerGroup + ps::kServerGroup + ps::kScheduler);
    }
    if (server_) server_->Run();
    ps::Finalize();
    if (server_) {
      delete server_;
    }
    server_ = nullptr;
  }

 private:


	typedef struct pushStruct{
	 int keys;
	 std::vector<NDArray> val;
	 int priority;
	  float average;
	bool doMerge;
  	}pushStruct;

/*
  typedef struct pushStructArray{
	  std::vector<pushStruct> array[11];//CHAR, INT8, INT16, INT32, INT64,UINT8, UINT16, UINT32, UINT64,FLOAT, DOUBLE,
	   //void push(pushStruct* i);
	 //  bool pop(pushStruct* i,double thres);
   }pushStructArray;
*/

static bool sortAvg(pushStruct i,pushStruct j){return i.average>j.average;}		//sort dscending

 static pushStruct* searchKey(std::vector<pushStruct>& arr,int key){
	//std::cout<<"vect"; 
	//for(size_t y=0;y<arr.size();y++)std::cout<<arr[y].keys<<"-"<<arr[y].average<<" ";
	//std::cout<<std::endl;
	for(size_t y=0;y<arr.size();y++){
		 if(arr[y].keys==key)
			 return &arr[y];
	}
	 return 0;
 }
/*
static size_t Size(NDArray& a) {
  size_t ret = 1;
  for (auto &i : a.shape()) ret *= i;
  return ret;
}*/

static double calculateavg(std::vector<NDArray>& vals){
	real_t sum=0;
	int count=0;
	//real_t *ptr=static_cast<real_t*>(vals.data().dptr_);
	size_t _si=vals.size();
	for(size_t y=0;y<_si;y++){
		real_t *ptr=static_cast<real_t*>(vals[y].data().dptr_);
		for(size_t k=0;k<vals[y].shape().Size();k++,count++)
		sum+=fabs(ptr[k]);
	}
	if(count==0)return -1;
	return  sum/count;//.Size();
}
void push(std::vector<pushStruct>& j,pushStruct& i){
	 //std::cout<<"Push Entry"<<std::endl;
	  if(j.empty())j.push_back(i);
	  else
	  {	
		  pushStruct* structptr=searchKey(j,i.keys);				//assuming same key same cb
		  if(structptr!=0){//std::cout<<"Push "<<std::endl;
			  //double sum=0;
				  for(size_t y=0;y< structptr->val.size();y++)
				  {// for(size_t z=0;z< structptr->val[y].shape().Size();z++)
				 structptr->val[y]+=i.val[y];//+structptr->val[y];
				  	 // sum+= structptr->val[y];
				  }//std::cout<<"end push"<<std::endl;
				  double avg=calculateavg(structptr->val);
		  		 if(avg!=-1)structptr->average=avg;
			}else
			  j.push_back(i);


	  }
	  std::sort(j.begin(),j.end(),sortAvg);
	//std::cout<<"push exit"<<std::endl;
}

void pop(std::vector<pushStruct>& j,float thres)
{
	pushStruct temp;
   while(j.size()>0 && (temp=j.front()).average>thres)
   {  // std::cout<<"Pop"<<std::endl;
	int key = temp.keys;
      const auto& vals = temp.val;
      NDArray merged = temp.doMerge?comm_->Reduce(key, vals, temp.priority): vals[0];

      auto& send_buf = comm_buf_[key];
      if (merged.ctx().dev_mask() == cpu::kDevMask) {
        send_buf = merged;  // avoid memory copy
      } else {
        if (send_buf.is_none()) {
          send_buf = NDArray(merged.shape(), pinned_ctx_);
        }
        CopyFromTo(merged, &send_buf);
      }

      // push to servers
      size_t size = send_buf.shape().Size();
      real_t* data = static_cast<real_t*>(send_buf.data().dptr_);
      auto push_to_servers =
          [this, key, data, size](RunContext rctx, Engine::CallbackOnComplete cb) {
         // convert to ps keys
        PSKV& pskv = EncodeKey(key, size);

        // do push. false means no delete
        ps::SArray<real_t> vals(data, size, false);
        CHECK_NOTNULL(ps_worker_)->ZPush(
        pskv.keys, vals, pskv.lens, 0, [cb]() { cb(); });
      };
      Engine::Get()->PushAsync(
          push_to_servers,
          pinned_ctx_,
          {send_buf.var()},
          {},
          FnProperty::kNormal,
          temp.priority,
          PROFILER_MESSAGE("KVStoreDistPush"));

	
	j.erase(j.begin());	
   	}

}


  void Push_(const std::vector<int>& keys,
             const std::vector<NDArray>& values,
             int priority,
             bool do_merge)  {
    // first aggregate the values over keys
	//std::cout<<"Push_\n";
	 float init_Threshold=dmlc::GetEnv("init_threshold",1.05);
	static std::vector<pushStruct> pushStruct_vector;
	static unsigned long iteration=1;
	double  thres= std::max(init_Threshold / sqrt(iteration),0.5/cbrt(iteration));
	pop(pushStruct_vector,thres);
    std::vector<int> uniq_keys;
    std::vector<std::vector<NDArray> > grouped_vals;
    GroupKVPairs(keys, values, &uniq_keys, &grouped_vals);
	NDArray *ptr;
	static int count=0;
       static int constKey=-1;
	count++;
    for (size_t i = 0; i < uniq_keys.size(); ++i) {
      // merge over devcies
	//std::cout<<do_merge<<std::endl;
        if(constKey==-1)constKey=uniq_keys[i];
	if(constKey==uniq_keys[i])iteration++;
	if(count>8){
		float avg=calculateavg(grouped_vals[i]);
		if(avg<thres)
		{
			pushStruct temp;
			temp.doMerge=do_merge;
			temp.keys=uniq_keys[i];
			temp.val=grouped_vals[i];
			temp.priority=priority;
			temp.average=avg;
			push(pushStruct_vector,temp);
			continue;

		}
	
	}



      int key = uniq_keys[i];
      const auto& vals = grouped_vals[i];
      NDArray merged = do_merge ? comm_->Reduce(key, vals, priority) : vals[0];

      auto& send_buf = comm_buf_[key];
      if (merged.ctx().dev_mask() == cpu::kDevMask) {
        send_buf = merged;  // avoid memory copy
      } else {
        if (send_buf.is_none()) {
          send_buf = NDArray(merged.shape(), pinned_ctx_);
        }
        CopyFromTo(merged, &send_buf);
      }
	//std::cout<<"Push3"<<std::endl;
      // push to servers
      size_t size = send_buf.shape().Size();
      real_t* data = static_cast<real_t*>(send_buf.data().dptr_);
      auto push_to_servers =
          [this, key, data, size](RunContext rctx, Engine::CallbackOnComplete cb) {
         // convert to ps keys
        PSKV& pskv = EncodeKey(key, size);
	//std::cout<<"Push2"<<std::endl;
        // do push. false means no delete
        ps::SArray<real_t> vals(data, size, false);
        CHECK_NOTNULL(ps_worker_)->ZPush(
        pskv.keys, vals, pskv.lens, 0, [cb]() { cb(); });
      };
      Engine::Get()->PushAsync(
          push_to_servers,
          pinned_ctx_,
          {send_buf.var()},
          {},
          FnProperty::kNormal,
          priority,
          PROFILER_MESSAGE("KVStoreDistPush"));
    }//std::cout<<"Push_ exit"<<std::endl;
  }

  /**
   * \brief check if the keys are all unique
   */
  void CheckUnique(const std::vector<int>& keys) {
    auto keys_copy = keys;
    auto last = std::unique(keys_copy.begin(), keys_copy.end());
    CHECK_EQ(static_cast<size_t>(std::distance(keys_copy.begin(), last)),
             static_cast<size_t>(keys.size()));
  }

  /**
   * \brief struct for ps keys and lens
   */
  struct PSKV {
    ps::SArray<ps::Key> keys;  // n keys
    ps::SArray<int> lens;  // the length of the i-th value
    int size;
  };

  /**
   * \brief cache all key partitions
   */
  std::unordered_map<int, PSKV> ps_kv_;

  /**
   * \brief serizelize EncodeKey
   */
  std::mutex mu_;

  /**
   * \brief convert to keys in ps
   */
  inline PSKV& EncodeKey(int key, size_t size) {
    mu_.lock();
    PSKV& pskv = ps_kv_[key];
    mu_.unlock();

    if (!pskv.keys.empty()) {
      CHECK_EQ(static_cast<size_t>(pskv.size), size) << "The value size cannot be changed";
    } else {
      auto krs = ps::Postoffice::Get()->GetServerKeyRanges();
      int num_servers = krs.size();
      CHECK_GT(num_servers, 0);

      // a simple heuristic for load balance
      if (size < bigarray_bound_) {
        // send it to a single random picked server
        int server = (key * 9973) % num_servers;
        ps::Key ps_key = krs[server].begin() + key;
        CHECK_LT(ps_key, krs[server].end());
        pskv.keys.push_back(ps_key);
        pskv.lens.push_back(size);
        pskv.size = size;
      } else {
        // parition it to all servers
        pskv.size = 0;
        for (int i = 0; i < num_servers; ++i) {
          size_t part_size =
              static_cast<size_t>(round(static_cast<double>(size)/num_servers*(i+1))) -
              static_cast<size_t>(round(static_cast<double>(size)/num_servers*i));
          ps::Key ps_key = krs[i].begin() + key;
          CHECK_LT(ps_key, krs[i].end());
          pskv.keys.push_back(ps_key);
          pskv.lens.push_back(part_size);
          pskv.size += part_size;
        }
        CHECK_EQ(static_cast<size_t>(pskv.size), size);
      }
    }
    return pskv;
  }

  /**
   * \brief for worker to push and pull data
   */
  ps::KVWorker<real_t>* ps_worker_;
  /**
   * \brief the server handle
   */
  KVStoreDistServer* server_;
  /**
   * \brief threshold for partition
   */
  size_t bigarray_bound_;
  /// \brief send & recver buffer
  std::unordered_map<int, NDArray> comm_buf_;
};

}  // namespace kvstore
}  // namespace mxnet


#endif  // MXNET_KVSTORE_KVSTORE_DIST_H_

